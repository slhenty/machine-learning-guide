{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pattern Guide to Machine Learning Models\n",
    "Steve Henty, 2022\n",
    "\n",
    "### Pattern Template\n",
    "\n",
    "**Name** (linear regression, logistic regression, classification, k-means, PCA, ...)\n",
    "- architecture (neural network, regression, SVM, ...)\n",
    "- type (supervised, unsupervised, ...)\n",
    "- use (real prediction, category classification, clustering, time-series prediction, ...)\n",
    "  - strength / weakness (aside from typical under- and over-fitting)\n",
    "- characteristics\n",
    "  - objective\n",
    "  - learning algorithm\n",
    "- mechanics\n",
    "  - foreward func / prediction\n",
    "  - loss function\n",
    "  - cost function\n",
    "  - backward func / learning\n",
    "  - parameters\n",
    "  - hyperparamters\n",
    "- evaluation\n",
    "  - bias / variance (aka under- / over-fitting)\n",
    "  - decision boundary\n",
    "  - learning curve\n",
    "  - error rate\n",
    "  - precision / recall\n",
    "- reference / library support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regression Patterns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Regression - univariate\n",
    "**Abbreviation**\n",
    "linreguni\n",
    "\n",
    "**Architecture**\n",
    "Polynomial in one variable (aka 'input feature')\n",
    "\n",
    "**Type**\n",
    "Supervised\n",
    "\n",
    "**Use**\n",
    "Real value prediction\n",
    "\n",
    "<u>_Weakness_</u>\n",
    "- underfits non-linear data (high bias)\n",
    "\n",
    "**Characteristics**\n",
    "<u>_Objective_</u>\n",
    "Tune a polynomial that takes the input feature, and returns a predicted output value\n",
    "\n",
    "<u>_Learning algorithm_</u>\n",
    "Gradient descent"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Mechanics**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Packages needed for the examples\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(seed=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<u>_Forward function / Prediction_</u>\n",
    "> $\\large\n",
    "\\begin{align}\n",
    "h_{\\theta}(x) &= \\theta_0 x_0 + \\theta_1 x_1 \\\\\n",
    "  &= \\theta \\cdot x \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "> where,\n",
    "> $\n",
    "\\begin{align}\n",
    "\\theta &\\text{ is a row vector of coefficients (parameters) of the polynomial } h_{\\theta}(x) \\\\\n",
    "x &\\text{ is a col vector with } x_0 \\text{ set to } 1\n",
    "\\end{align}\n",
    "$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Example linreguni-1:**\n",
    ">\n",
    "> Given,\n",
    "> $\n",
    "\\begin{align}\n",
    "\\theta &= \\begin{bmatrix}\n",
    "2 & 5\n",
    "\\end{bmatrix}\n",
    ",\\;\n",
    "x = \\begin{bmatrix}\n",
    "1 \\\\\n",
    "2\n",
    "\\end{bmatrix} \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "> Then,\n",
    "> $\n",
    "\\begin{align}\n",
    "\\theta \\cdot x &= \\begin{bmatrix} (\\theta_{[0,0]} \\times x_{[0,0]}) + (\\theta_{[0,1]} \\times x_{[1,0]}) \\end{bmatrix} \\\\\n",
    "  &= \\begin{bmatrix} (2 \\times 1) + (5 \\times 2) \\end{bmatrix} \\\\\n",
    "  &= \\begin{bmatrix} 2 + 10 \\end{bmatrix} \\\\\n",
    "  &= \\begin{bmatrix} 12 \\end{bmatrix}\n",
    "\\end{align}\n",
    "$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def h_theta (theta, features):\n",
    "  \"\"\"\n",
    "  :param theta: Row vector of polynomial coefficients (i.e. parameters)\n",
    "  :param features: Col vector of features, with x_0 set to 1 (i.e. bias term)\n",
    "  :return: Estimate of y (i.e. y_hat)\n",
    "  \"\"\"\n",
    "\n",
    "  y_hat = np.dot(theta, features)\n",
    "  return y_hat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta (shape):  (1, 2)\n",
      "[[2. 5.]] \n",
      "\n",
      "x (shape):  (1,)\n",
      "[2] \n",
      "\n",
      "x_bias (shape):  (1,)\n",
      "[1.] \n",
      "\n",
      "X (shape) with bias terms:  (2, 1)\n",
      "[[1.]\n",
      " [2.]] \n",
      "\n",
      "y_hat (shape):  (1, 1)\n",
      "[[12.]]\n"
     ]
    }
   ],
   "source": [
    "theta = np.array([[2., 5.]])\n",
    "x = np.array([2])\n",
    "x_bias = np.ones(x.shape[0])\n",
    "X = np.array([x_bias,x])\n",
    "print('theta (shape): ', theta.shape); print(theta, '\\n')\n",
    "print('x (shape): ', x.shape); print(x, '\\n')\n",
    "print('X (shape) with bias terms: ', X.shape); print(X, '\\n')\n",
    "\n",
    "y_hat = h_theta(theta, X)\n",
    "print ('y_hat (shape): ', y_hat.shape); print(y_hat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "_--- Vectorized (across samples) ---_\n",
    "> $\\large\n",
    "\\begin{align}\n",
    "h_{\\theta}(X) &= \\theta \\cdot X \\\\\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "> where,\n",
    "> $\n",
    "\\begin{align}\n",
    "\\theta &\\text{ is a row vector of coefficients (parameters) of the polynomial } h_{\\theta} \\\\\n",
    "X &\\text{ is a } n \\times m \\text{ matrix of samples} \\\\\n",
    "n &\\text{ is the number of features; for univariate, } n = 2, (x_0,\\;x_1) \\\\\n",
    "m &\\text{ is the number of samples}\n",
    "\\end{align}\n",
    "$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> **Example linreguni-2:**\n",
    ">\n",
    "> Given,\n",
    "> $\n",
    "\\begin{align}\n",
    "\\theta = \\begin{bmatrix}\n",
    "2 & 5\n",
    "\\end{bmatrix}\n",
    ",\\;\n",
    "X = \\begin{bmatrix}\n",
    "1 & 1 & 1 \\\\\n",
    "2 & 3 & 5 \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$\n",
    "> so $X$ contains three samples (the cols of $X$)\n",
    "\n",
    "\n",
    "> Then,\n",
    "> $\n",
    "\\begin{align}\n",
    "\\theta \\cdot X &= \\begin{bmatrix}\n",
    "  (\\theta_{[0,0]} \\times X_{[0,0]}) + (\\theta_{[0,1]} \\times X_{[1,0]}) &\n",
    "  (\\theta_{[0,0]} \\times X_{[0,1]}) + (\\theta_{[0,1]} \\times X_{[1,1]}) &\n",
    "  (\\theta_{[0,0]} \\times X_{[0,2]}) + (\\theta_{[0,1]} \\times X_{[1,2]})\n",
    "\\end{bmatrix} \\\\\n",
    "  &= \\begin{bmatrix}\n",
    "    (2 \\times 1) + (5 \\times 2) &\n",
    "    (2 \\times 1) + (5 \\times 3) &\n",
    "    (2 \\times 1) + (5 \\times 5)\n",
    "  \\end{bmatrix} \\\\\n",
    "  &= \\begin{bmatrix}\n",
    "    (2 + 10) & (2 + 15) & (2 + 25)\n",
    "  \\end{bmatrix} \\\\\n",
    "  &= \\begin{bmatrix}\n",
    "    12 & 17 & 27\n",
    "  \\end{bmatrix}\n",
    "\\end{align}\n",
    "$\n",
    "> so three predictions are returned (the cols of the result)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta (shape):  (1, 2)\n",
      "[[2. 5.]] \n",
      "\n",
      "x (shape):  (3,)\n",
      "[2 3 5] \n",
      "\n",
      "X (shape) with bias terms:  (2, 3)\n",
      "[[1. 1. 1.]\n",
      " [2. 3. 5.]] \n",
      "\n",
      "y_hat (shape):  (1, 3)\n",
      "[[12. 17. 27.]]\n"
     ]
    }
   ],
   "source": [
    "theta = np.array([[2., 5.]])\n",
    "x = np.array([2, 3, 5])\n",
    "x_bias = np.ones(x.shape[0])\n",
    "X = np.array([x_bias,x])\n",
    "print('theta (shape): ', theta.shape); print(theta, '\\n')\n",
    "print('x (shape): ', x.shape); print(x, '\\n')\n",
    "print('X (shape) with bias terms: ', X.shape); print(X, '\\n')\n",
    "\n",
    "y_hat = h_theta(theta, X)\n",
    "print ('y_hat (shape): ', y_hat.shape); print(y_hat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<u>_Loss function_</u>\n",
    "> $\\large\n",
    "\\begin{align}\n",
    "L_{\\theta}(x^{(i)}) &= h_{\\theta}(x^{(i)}) - y^{(i)}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "\n",
    "> where,\n",
    "> $\n",
    "\\begin{align}\n",
    "y &\\text{ is the training value that } h_{\\theta}(x) \\text{ should match} \\\\\n",
    "i &\\text{ is the index into } m \\text{ samples of } x\n",
    "\\end{align}\n",
    "$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<u>_Cost function_</u>\n",
    "> $\\large\n",
    "\\begin{align}\n",
    "J(\\theta) &= \\frac{1}{2m}\\sum\\limits_{i=1}^{m} L_{\\theta}(x^{(i)})^2 \\\\\n",
    "  &= \\frac{1}{2m}\\sum\\limits_{i=1}^{m} \\left[h_{\\theta}(x^{(i)}) - y^{(i)}\\right]^2\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "> where,\n",
    "> $\n",
    "\\begin{align}\n",
    "m &\\text{ is the number of samples,}\n",
    "\\end{align}\n",
    "$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<u>_Backward function / Learning / Parameter update_</u>\n",
    "> $\\large\n",
    "\\begin{align}\n",
    "\\theta_{j} &:= \\theta_{j} - \\alpha \\frac{1}{m}\\sum\\limits_{i=1}^{m} (\\hat{y}^{(i)} - y^{(i)})x_{j}^{(i)}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "> where,\n",
    "> $\n",
    "\\begin{align}\n",
    "\\theta &\\text{ is the set of parameters, i.e. polynomial coefficients} \\\\\n",
    "j &\\text{ is an index into the polynomial terms} \\\\\n",
    "m &\\text{ is the number of samples,} \\\\\n",
    "\\alpha &\\text{ is the learning rate}\n",
    "\\end{align}\n",
    "$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<u>_Parameters_</u>\n",
    "- polynomial co-efficients, $\\theta$\n",
    "\n",
    "<u>_Hyper-parameters_</u>\n",
    "- learning rate, alpha: $\\alpha$\n",
    "- polynomial degree / higher-order terms: $x_{j}^{p}$\n",
    "- (for multivariate:  $x_{j}^{p}x_{k}^{q}$)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}